{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Profile Likelihood from a series of SMC fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import re\n",
    "import scipy.stats as sts\n",
    "import xml.etree.ElementTree as ET\n",
    "import scipy.stats as sts\n",
    "import pickle\n",
    "import os\n",
    "from scipy.interpolate import UnivariateSpline\n",
    "from scipy.optimize import minimize_scalar, root_scalar\n",
    "\n",
    "\n",
    "import sys, importlib\n",
    "sys.path.append(\"..\")\n",
    "from evpytools import evplot\n",
    "from evpytools import auxiliary as aux\n",
    "from evpytools import definitions as defn\n",
    "for mod in [evplot, aux, defn]:\n",
    "    importlib.reload(mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size' : 18})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dupl = 10 ## number of repeated LL estimates at end of IPF\n",
    "\n",
    "sigmas = np.linspace(0.3, 0.8, 51)\n",
    "filenames = [f\"../data/out/ipf_result-sars_model_United_Kindom-B.1.1.7_sigma={sigma:g}.xml\" \n",
    "             for sigma in sigmas]\n",
    "\n",
    "for filename in filenames:\n",
    "    if not os.path.isfile(filename):\n",
    "        print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## extract final loglikes\n",
    "LLs = []\n",
    "LLvalids = []\n",
    "\n",
    "for filename in filenames:\n",
    "    tree = ET.parse(filename)\n",
    "    root = tree.getroot()\n",
    "    ## extract IPF steps\n",
    "    iterf_steps = root.findall(\"iterated_filtering_step\")\n",
    "    ## get log-like traces\n",
    "    ll_dicts = [xs.find(\"log_lik\").attrib for xs in iterf_steps]\n",
    "    ll_vals = [float(d[\"val\"]) for d in ll_dicts]\n",
    "    ll_valids = [True if d[\"finite\"] == 'true' else False for d in ll_dicts]\n",
    "    ## get final LL\n",
    "    final_lls = ll_vals[-dupl:]\n",
    "    final_lls_valid = ll_valids[-dupl:]\n",
    "    ## add final LL to list\n",
    "    LLs.append(final_lls)\n",
    "    LLvalids.append(final_lls_valid)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## export the LL values to a file\n",
    "with open(\"../data/out/prof-lik.tsv\", 'w') as f:\n",
    "    for s, xs, bs in zip(sigmas, LLs, LLvalids):\n",
    "        for x, b in zip(xs, bs):\n",
    "            f.write(f\"{s}\\t{x}\\t{b}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get median LLs\n",
    "\n",
    "meanLLs = [np.mean(lls) for lls in LLs]\n",
    "\n",
    "loLLs = [np.percentile(lls, 25) for lls in LLs]\n",
    "hiLLs = [np.percentile(lls, 75) for lls in LLs]\n",
    "\n",
    "maxDeltaLL = 20\n",
    "fidxs = [i for i, LL in enumerate(meanLLs) if np.max(meanLLs) - LL <= maxDeltaLL]\n",
    "\n",
    "fmeanLLs = [meanLLs[i] for i in fidxs]\n",
    "fsigmas = [sigmas[i] for i in fidxs]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## make a likelihood profile graph\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(7,5))\n",
    "ax.scatter(fsigmas, fmeanLLs, color='k', marker='o', label=\"mean\")\n",
    "## plot error bars for LL\n",
    "for s, l, h in zip(fsigmas, loLLs, hiLLs):\n",
    "    #ax.plot([s, s], [l, h], color='k')\n",
    "    pass\n",
    "\n",
    "## fit a spline through the points\n",
    "bounds = [fsigmas[0], fsigmas[-1]]\n",
    "cs = UnivariateSpline(fsigmas, fmeanLLs, s=2e1, ext='raise')\n",
    "xs = np.linspace(*bounds, 250)\n",
    "ax.plot(xs, cs(xs), label='spline', color='k', linewidth=2)\n",
    "\n",
    "\n",
    "## find max of spline and CI\n",
    "res = minimize_scalar(lambda x: -cs(x), bounds=bounds, method='bounded')\n",
    "max_LL = -res.fun\n",
    "sigma_opt = res.x\n",
    "\n",
    "ax.axvline(sigma_opt, color='k', linestyle='--')\n",
    "print(f\"s_opt = {sigma_opt:0.2f}\")\n",
    "print(f\"max LL = {max_LL:0.2f}\")\n",
    "\n",
    "DL = sts.chi2.ppf(0.95,1)/2\n",
    "\n",
    "lres = root_scalar(lambda x: cs(x)-max_LL + DL, bracket=[fsigmas[0], sigma_opt])\n",
    "rres = root_scalar(lambda x: cs(x)-max_LL + DL, bracket=[sigma_opt, fsigmas[-1]])\n",
    "\n",
    "lCI = lres.root\n",
    "rCI = rres.root\n",
    "\n",
    "print(f\"95% CI = [{lCI:0.2f}, {rCI:0.2f}]\")\n",
    "\n",
    "ax.axvspan(lCI, rCI, color='k', alpha=0.2, linewidth=0)\n",
    "\n",
    "ax.set_xlabel(\"$s$\")\n",
    "ax.set_ylabel(\"log-likelihood\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
