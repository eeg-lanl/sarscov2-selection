{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute profile likelihood and make figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import re\n",
    "import scipy.stats as sts\n",
    "import xml.etree.ElementTree as ET\n",
    "import scipy.stats as sts\n",
    "import pickle\n",
    "import glob\n",
    "import csv\n",
    "import string\n",
    "from scipy.interpolate import UnivariateSpline\n",
    "from scipy.optimize import minimize_scalar, root_scalar\n",
    "\n",
    "\n",
    "import sys, importlib\n",
    "sys.path.append(\"..\")\n",
    "from evpytools import evplot\n",
    "from evpytools import auxiliary as aux\n",
    "from evpytools import definitions as defn\n",
    "for mod in [evplot, aux, defn]:\n",
    "    importlib.reload(mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size' : 16})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import data\n",
    "def import_ll_data(ll_file):\n",
    "    with open(ll_file) as f:\n",
    "        ll_table = [row.split('\\t') for row in f.read().split('\\n') if row != '']\n",
    "    sigmas = aux.unique([float(row[0]) for row in ll_table])\n",
    "    ll_vals = [[float(row[1]) for row in ll_table if float(row[0]) == sigma] \n",
    "               for sigma in sigmas]\n",
    "    ll_oks = [[row[2] for row in ll_table if float(row[0]) == sigma] \n",
    "               for sigma in sigmas]\n",
    "    return sigmas, ll_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## place in row-major order!\n",
    "\n",
    "ll_files = [\n",
    "    \"../data/out/prof-lik-NL-D614G-wk.tsv\",\n",
    "    \"../data/out/prof-lik_Netherlands-B.1.1.7.tsv\",\n",
    "    \"../data/out/prof-lik_Netherlands-B.1.351.tsv\",\n",
    "    \"../data/out/prof-lik-UK-D614G-wk.tsv\",\n",
    "    \"../data/out/prof-lik_United_Kindom-B.1.1.7.tsv\",\n",
    "]\n",
    "\n",
    "IDs = [\"NL D614G\", \"NL B.1.1.7\", \"NL B.1.351\", \"UK D614G\", \"UK B.1.1.7\"]\n",
    "\n",
    "sigmass = []\n",
    "LLss = []\n",
    "\n",
    "for ll_file in ll_files:\n",
    "    sigmas, LLs = import_ll_data(ll_file)\n",
    "    sigmass.append(sigmas)\n",
    "    LLss.append(LLs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_prof_lik(ax, sigmas, LLs, spline_s, maxDL=10):\n",
    "    ## compute mean\n",
    "    meanLLs = [np.mean(lls) for lls in LLs]\n",
    "    ## filter\n",
    "    emL = np.max(meanLLs)\n",
    "    fidx = [i for i, l in enumerate(meanLLs) if l >= emL - maxDL]\n",
    "    fsigmas = [sigmas[i] for i in fidx]\n",
    "    fLLs = [meanLLs[i] for i in fidx]\n",
    "    ## plot mean\n",
    "    print(len(fsigmas), len(fLLs))\n",
    "    ax.scatter(fsigmas, fLLs, s=10, color='k', marker='o', label=\"mean\")\n",
    "    ## fit a spline through the points\n",
    "    bounds = [fsigmas[0], fsigmas[-1]]\n",
    "    cs = UnivariateSpline(fsigmas, fLLs, s=spline_s, ext='raise')\n",
    "    xs = np.linspace(*bounds, 250)\n",
    "    ax.plot(xs, cs(xs), label='spline', color='k', linewidth=2)\n",
    "\n",
    "    ## find max of spline and CI\n",
    "    res = minimize_scalar(lambda x: -cs(x), bounds=bounds, method='bounded')\n",
    "    max_LL = -res.fun\n",
    "    sigma_opt = res.x\n",
    "\n",
    "    ax.axvline(sigma_opt, color='k', linestyle='--')\n",
    "    print(f\"s_opt = {sigma_opt:0.2f}\")\n",
    "    print(f\"max LL = {max_LL:0.2f}\")\n",
    "\n",
    "    DL = sts.chi2.ppf(0.95,1)/2\n",
    "    \n",
    "    try:\n",
    "        lres = root_scalar(lambda x: cs(x)-max_LL + DL, bracket=[fsigmas[0], sigma_opt])\n",
    "        rres = root_scalar(lambda x: cs(x)-max_LL + DL, bracket=[sigma_opt, fsigmas[-1]])\n",
    "        \n",
    "        lCI = lres.root\n",
    "        rCI = rres.root\n",
    "\n",
    "        print(f\"95% CI = [{lCI:0.2f}, {rCI:0.2f}]\")\n",
    "\n",
    "        ax.axvspan(lCI, rCI, color='k', alpha=0.2, linewidth=0)\n",
    "    except:\n",
    "        print(\"unable to compute CI!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import other CIs\n",
    "\n",
    "with open(\"../data/in/CrIs.tsv\") as f:\n",
    "    reader = csv.DictReader(f, delimiter='\\t')\n",
    "    rows = [row for row in reader]\n",
    "    \n",
    "est_dict = {}\n",
    "\n",
    "for row in rows:\n",
    "    ID = row[\"region\"] + \" \" + row[\"variant\"]\n",
    "    med = float(row[\"median\"])\n",
    "    CI = [float(row[\"low\"]), float(row[\"high\"])]\n",
    "    est_dict[ID] = {\n",
    "        \"med\" : med,\n",
    "        \"CI\" : CI\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## make a likelihood profile graph\n",
    "\n",
    "numcols = 3\n",
    "numrows = len(IDs) // numcols + (1 if len(IDs) % numcols != 0 else 0)\n",
    "\n",
    "fig, axss = plt.subplots(numrows, numcols, figsize=(14,5), sharex=\"col\")\n",
    "\n",
    "axs = axss[::-1,:].flatten()\n",
    "\n",
    "for i, ax in enumerate(axs):\n",
    "    if i >= len(IDs):\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "for i, ID in enumerate(IDs):\n",
    "    plot_prof_lik(axs[i], sigmass[i], LLss[i], 2e1)\n",
    "    axs[i].set_title(IDs[i], fontsize=\"small\")\n",
    "\n",
    "## add secondary estimates\n",
    "\n",
    "CIpos = 1.1\n",
    "\n",
    "for i, ID in enumerate(IDs):\n",
    "    ymin, ymax = axs[i].get_ylim()\n",
    "    y = ymin + CIpos * (ymax - ymin)\n",
    "    xhat = est_dict[ID][\"med\"]\n",
    "    CI95 = est_dict[ID][\"CI\"]\n",
    "    axs[i].plot(CI95, [y, y], color='tab:red', zorder=2)\n",
    "    #CI90 = snd_CI90s[i]\n",
    "    #ax.plot(CI90, [y, y], color='tab:red', linewidth=4, zorder=2)\n",
    "    axs[i].scatter([xhat], [y], marker='o', color='tab:red', s=50, zorder=2)\n",
    "\n",
    "\n",
    "for ax in axss[-1]:\n",
    "    ax.set_xlabel(\"selection ($s$)\")\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "fig.text(0, 0.5, \"log-likelihood\", rotation=90, va='center')\n",
    "\n",
    "## add labels\n",
    "subplot_labels = string.ascii_uppercase\n",
    "\n",
    "for i, ax in enumerate(axss.flatten()[[0,1,3,4,5]]):\n",
    "    ax.text(-0.15, 1.0, subplot_labels[i], fontsize=22, transform=ax.transAxes)\n",
    "    \n",
    "fig.savefig(\"../data/out/FigProfLik.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
