{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute profile likelihood and make figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import re\n",
    "import scipy.stats as sts\n",
    "import xml.etree.ElementTree as ET\n",
    "import scipy.stats as sts\n",
    "import pickle\n",
    "import glob\n",
    "import csv\n",
    "from scipy.interpolate import UnivariateSpline\n",
    "from scipy.optimize import minimize_scalar, root_scalar\n",
    "\n",
    "\n",
    "import sys, importlib\n",
    "sys.path.append(\"..\")\n",
    "from evpytools import evplot\n",
    "from evpytools import auxiliary as aux\n",
    "from evpytools import definitions as defn\n",
    "for mod in [evplot, aux, defn]:\n",
    "    importlib.reload(mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size' : 18})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import data\n",
    "def import_ll_data(ll_file):\n",
    "    with open(ll_file) as f:\n",
    "        ll_table = [row.split('\\t') for row in f.read().split('\\n') if row != '']\n",
    "    sigmas = aux.unique([float(row[0]) for row in ll_table])\n",
    "    ll_vals = [[float(row[1]) for row in ll_table if float(row[0]) == sigma] \n",
    "               for sigma in sigmas]\n",
    "    ll_oks = [[row[2] for row in ll_table if float(row[0]) == sigma] \n",
    "               for sigma in sigmas]\n",
    "    return sigmas, ll_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ll_file_reg1 = \"../data/out/prof-lik-UK-D614G-wk.tsv\"\n",
    "#ll_file_reg2 = \"../data/out/prof-lik-NL-D614G-wk.tsv\"\n",
    "\n",
    "ll_file_reg1 = \"../data/out/prof-lik-UK-B117-wk-long.tsv\"\n",
    "ll_file_reg2 = \"../data/out/prof-lik-NL-B117-wk-long.tsv\"\n",
    "\n",
    "\n",
    "sigmas_reg1, LLs_reg1 = import_ll_data(ll_file_reg1)\n",
    "sigmas_reg2, LLs_reg2 = import_ll_data(ll_file_reg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_prof_lik(ax, sigmas, LLs, spline_s, bounds=None):\n",
    "    if bounds is None:\n",
    "        fLLs = LLs\n",
    "        fsigmas = sigmas\n",
    "    else:\n",
    "        l, r = bounds\n",
    "        fLLs = LLs[l:r]\n",
    "        fsigmas = sigmas[l:r]\n",
    "    ## compute mean\n",
    "    meanLLs = [np.mean(lls) for lls in fLLs]\n",
    "    loLLs = [np.percentile(lls, 25) for lls in fLLs]\n",
    "    hiLLs = [np.percentile(lls, 75) for lls in fLLs]\n",
    "    ## plot mean\n",
    "    ax.scatter(fsigmas, meanLLs, color='k', marker='o', label=\"mean\")\n",
    "    ## plot error bars for LL\n",
    "    for s, l, h in zip(fsigmas, loLLs, hiLLs):\n",
    "        #ax.plot([s, s], [l, h], color='k')\n",
    "        pass\n",
    "\n",
    "    ## fit a spline through the points\n",
    "    bounds = [fsigmas[0], fsigmas[-1]]\n",
    "    cs = UnivariateSpline(fsigmas, meanLLs, s=spline_s, ext='raise')\n",
    "    xs = np.linspace(*bounds, 250)\n",
    "    ax.plot(xs, cs(xs), label='spline', color='k', linewidth=2)\n",
    "\n",
    "    ## find max of spline and CI\n",
    "    res = minimize_scalar(lambda x: -cs(x), bounds=bounds, method='bounded')\n",
    "    max_LL = -res.fun\n",
    "    sigma_opt = res.x\n",
    "\n",
    "    ax.axvline(sigma_opt, color='k', linestyle='--')\n",
    "    print(f\"s_opt = {sigma_opt:0.2f}\")\n",
    "    print(f\"max LL = {max_LL:0.2f}\")\n",
    "\n",
    "    DL = sts.chi2.ppf(0.95,1)/2\n",
    "    \n",
    "    try:\n",
    "        lres = root_scalar(lambda x: cs(x)-max_LL + DL, bracket=[fsigmas[0], sigma_opt])\n",
    "        rres = root_scalar(lambda x: cs(x)-max_LL + DL, bracket=[sigma_opt, fsigmas[-1]])\n",
    "        \n",
    "        lCI = lres.root\n",
    "        rCI = rres.root\n",
    "\n",
    "        print(f\"95% CI = [{lCI:0.2f}, {rCI:0.2f}]\")\n",
    "\n",
    "        ax.axvspan(lCI, rCI, color='k', alpha=0.2, linewidth=0)\n",
    "    except:\n",
    "        print(\"unable to compute CI!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import other CIs\n",
    "\n",
    "#variant = \"D614G\"\n",
    "variant = \"B.1.1.7\"\n",
    "\n",
    "with open(\"../data/in/estimates-popgen-NL-UK.tsv\") as f:\n",
    "    reader = csv.DictReader(f, delimiter='\\t')\n",
    "    rows = [row for row in reader if row[\"variant\"] == variant]\n",
    "    \n",
    "regions = [\"United Kingdom\", \"Netherlands\"]\n",
    "\n",
    "snd_estimates = [next(filter(lambda x: x[\"region\"] == region, rows))\n",
    "                 for region in regions]\n",
    "\n",
    "snd_point_estimates = [float(row[\"estimate\"]) for row in snd_estimates]\n",
    "snd_CI95s = [(float(row[\"low95\"]), float(row[\"high95\"])) for row in snd_estimates]\n",
    "snd_CI90s = [(float(row[\"low90\"]), float(row[\"high90\"])) for row in snd_estimates]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## make a likelihood profile graph\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(14,5))\n",
    "\n",
    "#D614G\n",
    "#bounds1 = (7,-7)\n",
    "#bounds2 = (6,-6)\n",
    "\n",
    "#B117\n",
    "bounds1 = (15,-5)\n",
    "bounds2 = (None,-8)\n",
    "\n",
    "\n",
    "plot_prof_lik(axs[0], sigmas_reg1, LLs_reg1, 10, bounds=bounds1)\n",
    "plot_prof_lik(axs[1], sigmas_reg2, LLs_reg2, 10, bounds=bounds2)\n",
    "\n",
    "## add secondary estimates\n",
    "\n",
    "CIpos = 1.1\n",
    "\n",
    "for i, ax in enumerate(axs):\n",
    "    ymin, ymax = ax.get_ylim()\n",
    "    y = ymin + CIpos * (ymax - ymin)\n",
    "    xhat = snd_point_estimates[i]\n",
    "    CI95 = snd_CI95s[i]\n",
    "    ax.plot(CI95, [y, y], color='tab:red', zorder=2)\n",
    "    CI90 = snd_CI90s[i]\n",
    "    ax.plot(CI90, [y, y], color='tab:red', linewidth=4, zorder=2)\n",
    "    ax.scatter([xhat], [y], marker='o', color='tab:red', s=50, zorder=2)\n",
    "\n",
    "\n",
    "for ax in axs:\n",
    "    ax.set_xlabel(\"$s$\")\n",
    "\n",
    "axs[0].set_ylabel(\"log-likelihood\")\n",
    "\n",
    "axs[0].set_title(\"United Kingdom\")\n",
    "axs[1].set_title(\"Netherlands\")\n",
    "\n",
    "fig.savefig(\"../data/out/figures/Fig2RegionsProfLik.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
