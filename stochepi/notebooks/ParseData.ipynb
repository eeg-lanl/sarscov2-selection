{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse the pango dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import datetime\n",
    "import scipy.stats as sts\n",
    "import os\n",
    "\n",
    "import sys, importlib\n",
    "sys.path.append(\"..\")\n",
    "from evpytools import evplot\n",
    "from evpytools import auxiliary as aux\n",
    "from evpytools import definitions as defn\n",
    "for mod in [evplot, aux, defn]:\n",
    "    importlib.reload(mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_date(s):\n",
    "    if \"-\" in s:\n",
    "        return datetime.datetime.strptime(s, \"%Y-%m-%d\")\n",
    "    elif \"/\" in s:\n",
    "        return datetime.datetime.strptime(s, \"%m/%d/%y\")\n",
    "    else:\n",
    "        raise Exception(\"unknown date format!\")\n",
    "\n",
    "date0 = parse_date(\"2020-01-01\")\n",
    "\n",
    "def cumul_to_daily(xs):\n",
    "    ys = np.array([0] + xs)\n",
    "    return list(ys[1:] - ys[:-1])\n",
    "\n",
    "def extract_variant_timeseries(country, variants, data_dicts):\n",
    "    if type(variants) is not list:\n",
    "        variants = [variants]\n",
    "    sel_keys = [\"Day\", \"Total\"] + variants\n",
    "\n",
    "    ## filter region\n",
    "    sel_data_dicts = [\n",
    "        {k : dd[k] for k in sel_keys} \n",
    "        for dd in data_dicts if dd[\"Country\"] == country\n",
    "    ]\n",
    "\n",
    "    dates = [parse_date(dd[\"Day\"]) for dd in sel_data_dicts]\n",
    "    days = [(date - date0).days for date in dates]\n",
    "    timeseries_dict = {\n",
    "        \"days\" : days,\n",
    "        \"dates\" : dates,\n",
    "        \"Total\" : [int(dd[\"Total\"]) for dd in sel_data_dicts]\n",
    "    }\n",
    "    timeseries_dict.update({\n",
    "        variant : [int(dd[variant]) for dd in sel_data_dicts]\n",
    "        for variant in variants\n",
    "    })\n",
    "    return timeseries_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"../data/in/pango_2021-05-20.csv\"\n",
    "\n",
    "with open(filename) as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    data_dicts = [row for row in reader]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#variants = [\"B.1.617.2\"] ## delta\n",
    "#variants = [\"B.1.1.7\"] ## alpha\n",
    "#variants = [\"B.1.351\"]\n",
    "variants = [\"R.1\"]\n",
    "\n",
    "#country = \"United Kingdom\"\n",
    "#country = \"Netherlands\"\n",
    "country = \"Japan\"\n",
    "\n",
    "timeseries_dict = extract_variant_timeseries(country, variants, data_dicts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import JHU data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = os.path.expanduser(\"~/Repositories/clones/COVID-19/\" + \\\n",
    "    \"csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_global.csv\")\n",
    "\n",
    "with open(filename) as f:\n",
    "    reader = csv.reader(f)\n",
    "    epi_data = [row for row in reader]\n",
    "epi_header = epi_data[0]\n",
    "epi_data = epi_data[1:]\n",
    "epi_dates = [parse_date(d) for d in epi_header[4:]]\n",
    "epi_days = [(date - date0).days for date in epi_dates]\n",
    "\n",
    "sel_epi_data = [row for row in epi_data if row[1] == country and row[0] == \"\"][0]\n",
    "death_incidence_cumul = [int(x) for x in sel_epi_data[4:]]\n",
    "death_incidence = cumul_to_daily(death_incidence_cumul)\n",
    "\n",
    "## remove outliers\n",
    "\n",
    "def get_rav(xs, w=3):\n",
    "    ys = [(np.sum(xs[i-w : i+w+1]) - xs[i])//(2*w) for i in range(len(xs))]\n",
    "    return ys\n",
    "\n",
    "ra_inc = get_rav(death_incidence)\n",
    "\n",
    "for i in range(len(death_incidence)):\n",
    "    if 3 * ra_inc[i] < death_incidence[i]:\n",
    "        death_incidence[i] = ra_inc[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 1, figsize=(7,7))\n",
    "\n",
    "days = timeseries_dict[\"days\"]\n",
    "Ftot = timeseries_dict[\"Total\"]\n",
    "Fvars = [timeseries_dict[var] for var in variants]\n",
    "\n",
    "axs[0].plot(days, Ftot)\n",
    "for Fvar in Fvars:\n",
    "    axs[0].plot(days, Fvar)\n",
    "\n",
    "fvars = [[n/N for n, N in zip(Fvar, Ftot)] for Fvar in Fvars]\n",
    "\n",
    "for fvar in fvars:\n",
    "    axs[1].plot(days, fvar)\n",
    "\n",
    "    \n",
    "axs[2].plot(epi_days, death_incidence)\n",
    "\n",
    "axs[0].set_ylabel(\"num seq.\")\n",
    "axs[1].set_ylabel(\"freq mutant seq.\")\n",
    "axs[2].set_ylabel(\"death incidence\")\n",
    "\n",
    "fig.savefig(\"../seq-abs-rel_death.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Week-level data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## week starts on a monday. \n",
    "\n",
    "mondays = [date for date in epi_dates if date.weekday() == 0]\n",
    "days_week = [(date - date0).days for date in mondays]\n",
    "\n",
    "dates_per_week = {\n",
    "    mon : [date for date in epi_dates if date >= mon and date < mon + datetime.timedelta(days=7)]\n",
    "    for mon in mondays\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## week-level variant data\n",
    "\n",
    "def aggregate_counts(ds, xs, dates, date_dict):\n",
    "    dx_dict = dict(zip(ds, xs))\n",
    "    return [np.sum([dx_dict[d] if d in dx_dict else 0 \n",
    "                    for d in date_dict[d0]]) for d0 in dates]\n",
    "\n",
    "\n",
    "timeseries_dict_week = {\n",
    "    \"dates\" : mondays,\n",
    "    \"days\" : days_week,\n",
    "}\n",
    "\n",
    "for var in variants + [\"Total\"]:\n",
    "    timeseries_dict_week[var] = \\\n",
    "        aggregate_counts(timeseries_dict[\"dates\"], \n",
    "                         timeseries_dict[var], mondays, dates_per_week)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## week-level epi data\n",
    "\n",
    "death_incidence_week = aggregate_counts(epi_dates, death_incidence, \n",
    "                                        mondays, dates_per_week)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3,1, figsize=(25,7))\n",
    "\n",
    "days = timeseries_dict_week[\"days\"]\n",
    "Ftot = timeseries_dict_week[\"Total\"]\n",
    "Fvars = [timeseries_dict_week[var] for var in variants]\n",
    "\n",
    "axs[0].plot(days, Ftot, color='k')\n",
    "for Fvar in Fvars:\n",
    "    axs[0].plot(days, Fvar)\n",
    "\n",
    "fvars = [[n/N for n, N in zip(Fvar, Ftot)] for Fvar in Fvars]\n",
    "civars = [[sts.beta.interval(0.95, n+0.5, N-n+0.5) \n",
    "           for n, N in zip(Fvar, Ftot)] for Fvar in Fvars]\n",
    "\n",
    "\n",
    "for fvar in fvars:\n",
    "    axs[1].plot(days, fvar)\n",
    "    \n",
    "for civar in civars:\n",
    "    for t, CI in zip(days, civar):\n",
    "        axs[1].plot([t,t], CI, color='k')\n",
    "\n",
    "\n",
    "axs[2].plot(days_week, death_incidence_week, marker='o', markersize=3)\n",
    "\n",
    "## B.1.1.7\n",
    "#idx0 = 31 \n",
    "#num_weeks = 29\n",
    "\n",
    "## B.1.351\n",
    "#idx0 = 44\n",
    "#num_weeks = 20\n",
    "\n",
    "## R.1\n",
    "idx0 = 43\n",
    "num_weeks = 18\n",
    "\n",
    "\n",
    "t0 = days_week[idx0]\n",
    "tend = days_week[idx0 + num_weeks]\n",
    "print(\"t0 =\", t0, \"tend = \", tend)\n",
    "\n",
    "for ax in axs:\n",
    "    ax.axvline(x=days_week[idx0])\n",
    "    ax.axvline(x=days_week[idx0 + num_weeks])\n",
    "    \n",
    "axs[-1].set_xticks(days_week)\n",
    "axs[-1].set_xticklabels(days_week, rotation=90)\n",
    "\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## make dataset for SMC\n",
    "\n",
    "var = variants[0]\n",
    "\n",
    "country_fn = country.replace(\" \", \"_\")\n",
    "\n",
    "ev = \"[RESET_CASES]\"\n",
    "with open(f\"../data/in/sars2-seq-death-week-{country_fn}-{var}.tsv\", 'w') as f:\n",
    "    for i in range(len(days_week)):\n",
    "        t = days_week[i]\n",
    "        D = death_incidence_week[i]\n",
    "        N = timeseries_dict_week[\"Total\"][i]\n",
    "        n = timeseries_dict_week[var][i]\n",
    "        c = defn.uncensored_code\n",
    "        if t <= t0 or t > tend:\n",
    "            continue\n",
    "        ## else...\n",
    "        line = f\"{country_fn}\\t{t}\\t{ev}\\t{D}\\t{c}\\t{n}\\t{c}\\t{N}\\t{c}\"\n",
    "        f.write(line + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
