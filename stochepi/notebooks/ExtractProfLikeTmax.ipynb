{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Profile Likelihood for the SARS-CoV-2 variant model\n",
    "\n",
    "Compute the profile likelihood with data restricted such that $t \\leq t_{\\max}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import re\n",
    "import scipy.stats as sts\n",
    "import xml.etree.ElementTree as ET\n",
    "import scipy.stats as sts\n",
    "import pickle\n",
    "import glob\n",
    "from scipy.interpolate import UnivariateSpline\n",
    "from scipy.optimize import minimize_scalar, root_scalar\n",
    "\n",
    "\n",
    "import sys, importlib\n",
    "sys.path.append(\"..\")\n",
    "from evpytools import evplot\n",
    "from evpytools import auxiliary as aux\n",
    "from evpytools import definitions as defn\n",
    "for mod in [evplot, aux, defn]:\n",
    "    importlib.reload(mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size' : 18})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dupl = 2 ## number of repeated LL estimates at end of IPF\n",
    "\n",
    "sigmas = np.linspace(0.1, 0.7, 26)\n",
    "tmaxs = np.linspace() ## TODO\n",
    "filenames = [[f\"../data/out/ipf_result-sars_model_sigma={sigma:g}.xml\" \n",
    "              for sigma in sigmas] for tmax in txmaxs]\n",
    "\n",
    "print(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: use glob and re to get sigmas and files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## extract final loglikes\n",
    "LLs = []\n",
    "LLvalids = []\n",
    "\n",
    "for filename in filenames:\n",
    "    tree = ET.parse(filename)\n",
    "    root = tree.getroot()\n",
    "    ## extract IPF steps\n",
    "    iterf_steps = root.findall(\"iterated_filtering_step\")\n",
    "    ## get log-like traces\n",
    "    ll_dicts = [xs.find(\"log_lik\").attrib for xs in iterf_steps]\n",
    "    ll_vals = [float(d[\"val\"]) for d in ll_dicts]\n",
    "    ll_valids = [True if d[\"finite\"] == 'true' else False for d in ll_dicts]\n",
    "    ## get final LL\n",
    "    final_lls = ll_vals[-dupl:]\n",
    "    final_lls_valid = ll_valids[-dupl:]\n",
    "    ## add final LL to list\n",
    "    LLs.append(final_lls)\n",
    "    LLvalids.append(final_lls_valid)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## export the LL values to a file\n",
    "with open(\"../data/out/prof-lik-UK-N501Y.tsv\", 'w') as f:\n",
    "    for s, xs, bs in zip(sigmas, LLs, LLvalids):\n",
    "        for x, b in zip(xs, bs):\n",
    "            f.write(f\"{s}\\t{x}\\t{b}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get median LLs\n",
    "\n",
    "fsigmas = sigmas\n",
    "fLLs = LLs\n",
    "\n",
    "meanLLs = [np.mean(lls) for lls in fLLs]\n",
    "loLLs = [np.percentile(lls, 25) for lls in fLLs]\n",
    "hiLLs = [np.percentile(lls, 75) for lls in fLLs]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## make a likelihood profile graph\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(7,5))\n",
    "ax.scatter(fsigmas, meanLLs, color='k', marker='o', label=\"mean\")\n",
    "## plot error bars for LL\n",
    "for s, l, h in zip(fsigmas, loLLs, hiLLs):\n",
    "    #ax.plot([s, s], [l, h], color='k')\n",
    "    pass\n",
    "\n",
    "## fit a spline through the points\n",
    "bounds = [fsigmas[0], fsigmas[-1]]\n",
    "cs = UnivariateSpline(fsigmas, meanLLs, s=1e3, ext='raise')\n",
    "xs = np.linspace(*bounds, 250)\n",
    "ax.plot(xs, cs(xs), label='spline', color='k', linewidth=2)\n",
    "\n",
    "\n",
    "## find max of spline and CI\n",
    "res = minimize_scalar(lambda x: -cs(x), bounds=bounds, method='bounded')\n",
    "max_LL = -res.fun\n",
    "sigma_opt = res.x\n",
    "\n",
    "ax.axvline(sigma_opt, color='k', linestyle='--')\n",
    "print(f\"s_opt = {sigma_opt:0.2f}\")\n",
    "print(f\"max LL = {max_LL:0.2f}\")\n",
    "\n",
    "DL = sts.chi2.ppf(0.95,1)/2\n",
    "\n",
    "lres = root_scalar(lambda x: cs(x)-max_LL + DL, bracket=[fsigmas[0], sigma_opt])\n",
    "rres = root_scalar(lambda x: cs(x)-max_LL + DL, bracket=[sigma_opt, fsigmas[-1]])\n",
    "\n",
    "lCI = lres.root\n",
    "rCI = rres.root\n",
    "\n",
    "print(f\"95% CI = [{lCI:0.2f}, {rCI:0.2f}]\")\n",
    "\n",
    "ax.axvspan(lCI, rCI, color='k', alpha=0.2, linewidth=0)\n",
    "\n",
    "ax.set_xlabel(\"$s$\")\n",
    "ax.set_ylabel(\"log-likelihood\")\n",
    "\n",
    "#ax.legend()\n",
    "\n",
    "fig.savefig(\"../data/out/profile-likelihood-s.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
